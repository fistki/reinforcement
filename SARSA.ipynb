{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fistki/reinforcement/blob/main/SARSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QliyluixW1MX"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install gym\n",
        "3# !pip install numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "TRZCLz67hlRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "# from IPython.display import HTML\n",
        "from IPython import display\n",
        "import torch\n",
        "\n",
        "\n",
        "def running_mean(x, N=50):\n",
        "    kernel = np.ones(N)\n",
        "    conv_len = x.shape[0]-N\n",
        "    y = np.zeros(conv_len)\n",
        "    for i in range(conv_len):\n",
        "        y[i] = kernel @ x[i:i+N]\n",
        "        y[i] /= N\n",
        "    return y\n",
        "\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    patch = plt.imshow(frames[0][0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i][0])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames=len(frames), interval=10)\n",
        "\n",
        "    video = anim.to_html5_video()\n",
        "    html = display.HTML(video)\n",
        "    display.display(html)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def minigrid_test_model(env, model, mode='static', loss_lim=15, display=True):\n",
        "    action_set = {\n",
        "        0: 'u',\n",
        "        1: 'd',\n",
        "        2: 'l',\n",
        "        3: 'r',\n",
        "    }\n",
        "\n",
        "    i = 0\n",
        "    test_game = env(mode=mode)\n",
        "    state = test_game.board.render_np().reshape(1, 64) + np.random.rand(1, 64) / 10.0\n",
        "    state = torch.from_numpy(state).float()\n",
        "\n",
        "    if display:\n",
        "        print(\"Initial State:\")\n",
        "        print(test_game.display())\n",
        "\n",
        "    status = 1\n",
        "    while status == 1:\n",
        "        qval = model(state)\n",
        "        qval_ = qval.data.numpy()\n",
        "        action_ = np.argmax(qval_)\n",
        "        action = action_set[action_]\n",
        "\n",
        "        if display:\n",
        "            print('Move #: %s; Taking action: %s' % (i, action))\n",
        "        test_game.makeMove(action)\n",
        "\n",
        "        state_ = test_game.board.render_np().reshape(1, 64) + np.random.rand(1, 64) / 10.0\n",
        "        state = torch.from_numpy(state_).float()\n",
        "\n",
        "        if display:\n",
        "            print(test_game.display())\n",
        "        reward = test_game.reward()\n",
        "        if reward != -1:\n",
        "            if reward > 0:\n",
        "                status = 2\n",
        "                if display:\n",
        "                    print(\"Game won! Reward: %s\" % (reward,))\n",
        "            else:\n",
        "                status = 0\n",
        "                if display:\n",
        "                    print(\"Game LOST. Reward: %s\" % (reward,))\n",
        "        i += 1\n",
        "\n",
        "        if i > loss_lim:\n",
        "            if display:\n",
        "                print(\"Game lost; too many moves.\")\n",
        "            break\n",
        "\n",
        "    win = True if status == 2 else False\n",
        "    return win\n",
        "\n",
        "\n",
        "def cartpole_train_graph(score):\n",
        "    score = np.array(score)\n",
        "    avg_score = running_mean(score, 50)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.ylabel(\"Episode Duration\", fontsize=22)\n",
        "    plt.xlabel(\"Training Epochs\", fontsize=22)\n",
        "    plt.plot(avg_score, color='green')\n",
        "\n",
        "\n",
        "def cartpole_test_scatter(env, model, MAX_DUR=500):\n",
        "    score = []\n",
        "    games = 100\n",
        "    done = False\n",
        "    state1 = env.reset()\n",
        "    for i in range(games):\n",
        "        t = 0\n",
        "        while not done:\n",
        "            pred = model(torch.from_numpy(state1).float())\n",
        "            action = np.random.choice(np.array([0, 1]), p=pred.data.numpy())\n",
        "            state2, reward, done, truncated = env.step(action)\n",
        "            state1 = state2\n",
        "            t += 1\n",
        "            if t > MAX_DUR:\n",
        "                break\n",
        "\n",
        "        state1 = env.reset()\n",
        "        done = False\n",
        "        score.append(t)\n",
        "    score = np.array(score)\n",
        "    plt.scatter(np.arange(score.shape[0]), score)\n",
        "\n",
        "\n",
        "def cartpole_test_scatter_a2c(env, model, MAX_DUR=500):\n",
        "    score = []\n",
        "    games = 100\n",
        "    done = False\n",
        "    state1 = env.reset()\n",
        "\n",
        "    for i in range(games):\n",
        "        t = 0\n",
        "        while not done:\n",
        "            logits, value = model(torch.from_numpy(state1).float())\n",
        "            action_dist = torch.distributions.Categorical(logits=logits)\n",
        "            action = action_dist.sample()\n",
        "            state2, reward, done, truncated = env.step(action.detach().numpy())\n",
        "            state1 = state2\n",
        "\n",
        "            t += 1\n",
        "            if t > MAX_DUR:\n",
        "                break\n",
        "\n",
        "        state1 = env.reset()\n",
        "        done = False\n",
        "        score.append(t)\n",
        "\n",
        "    score = np.array(score)\n",
        "    plt.scatter(np.arange(score.shape[0]), score)\n",
        "\n",
        "\n",
        "def cartpole_test_video(env, model, MAX_DUR=500):\n",
        "    done = False\n",
        "    frames = []\n",
        "    t = 0\n",
        "    state1 = env.reset()\n",
        "    while not done:\n",
        "        frames.append(env.render())\n",
        "        pred = model(torch.from_numpy(state1).float())\n",
        "        action = np.random.choice(np.array([0, 1]), p=pred.data.numpy())\n",
        "        state2, reward, done, truncated = env.step(action)\n",
        "        state1 = state2\n",
        "        t += 1\n",
        "        if t > MAX_DUR:  # L\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    print(f\"Episode length : {t}\")\n",
        "\n",
        "    display_frames_as_gif(frames)\n",
        "\n",
        "\n",
        "def cartpole_test_video_a2c(env, model, MAX_DUR=500):\n",
        "    done = False\n",
        "    frames = []\n",
        "    t = 0\n",
        "    state1 = env.reset()\n",
        "\n",
        "    while not done:\n",
        "        frames.append(env.render())\n",
        "        logits, value = model(torch.from_numpy(state1).float())\n",
        "        action_dist = torch.distributions.Categorical(logits=logits)\n",
        "        action = action_dist.sample()\n",
        "        state2, reward, done, truncated = env.step(action.detach().numpy())\n",
        "        state1 = state2\n",
        "        t += 1\n",
        "        if t > MAX_DUR:  # L\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    print(f\"Episode length : {t}\")\n",
        "\n",
        "    display_frames_as_gif(frames)"
      ],
      "metadata": {
        "id": "V7L76Bw5hqc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARSA"
      ],
      "metadata": {
        "id": "3TwDMhlrhrPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import gym\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "QxobB_Dy055Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, num_states, num_actions):\n",
        "\n",
        "    # update function\n",
        "\n",
        "    # decrease_epsilon function\n",
        "\n",
        "    # act function\n",
        ""
      ],
      "metadata": {
        "id": "tLJg4Ofi04oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import wrappers\n",
        "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
        "observation = env.reset()\n",
        "agent = Agent(4,2)"
      ],
      "metadata": {
        "id": "YM5mNttf0-mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training SARSA"
      ],
      "metadata": {
        "id": "21y4IB0R1AEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing SARSA\n",
        "\n",
        "def cartpole_test_video_sarsa(env, agent, MAX_DUR=500):\n",
        "    done = False\n",
        "    frames = []\n",
        "    t = 0\n",
        "    obs = torch.FloatTensor(env.reset())\n",
        "    while not done:\n",
        "        frames.append(env.render())\n",
        "        # 1. get action from agent\n",
        "        # 2. get next_obs from environment\n",
        "        obs = next_obs\n",
        "\n",
        "        t += 1\n",
        "        if t > MAX_DUR:  # L\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "    print(f\"Episode length : {t}\")\n",
        "\n",
        "    display_frames_as_gif(frames)\n",
        "\n",
        "\n",
        "cartpole_test_video_Sarsa(env=env, agent=agent, MAX_DUR=500)"
      ],
      "metadata": {
        "id": "YgEFgOG1hvWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OHsPFiViWT-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}